{
  "exam": {
    "id": "aws-mla-c01-set3-ja",
    "name": "AWS MLA-C01 模擬試験 #3",
    "code": "MLA-C01",
    "provider": "AWS",
    "language": "ja",
    "description": "AWS認定 機械学習エンジニア - アソシエイト模擬試験 - セット3",
    "totalQuestions": 40,
    "passingScore": 70,
    "examTime": 170,
    "domains": [
      {
        "id": 1,
        "name": "ML用データ準備",
        "weight": 28
      },
      {
        "id": 2,
        "name": "MLモデル開発",
        "weight": 26
      },
      {
        "id": 3,
        "name": "MLモデルのデプロイとオーケストレーション",
        "weight": 22
      },
      {
        "id": 4,
        "name": "MLソリューションの監視とメンテナンス",
        "weight": 24
      }
    ],
    "tags": [
      "AWS",
      "機械学習",
      "SageMaker",
      "アソシエイト"
    ]
  },
  "questions": [
    {
      "id": "q1",
      "domain": 1,
      "question": "企業がIoTデバイスからのストリーミングデータに対してほぼリアルタイムで特徴量エンジニアリングを実行する必要があります。どのAWSサービスの組み合わせを使用すべきですか？",
      "options": {
        "A": "Amazon Kinesis Data StreamsとAWS Lambda",
        "B": "Amazon S3とAWS Batch",
        "C": "Amazon RDSとスケジュールされたクエリ",
        "D": "Amazon DynamoDBとトリガー"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "Kinesis Data StreamsとLambdaはリアルタイムの特徴量エンジニアリングを可能にします：\n- Kinesisがストリーミングデータを取り込む\n- Lambdaがリアルタイムでデータを処理・変換\n- Feature Store Onlineに特徴量を保存可能\n- 低レイテンシー処理\n\nS3とBatch (B)はバッチ処理用です。RDS (C)はストリーミング用ではありません。DynamoDBトリガー (D)はイベントベースです。",
      "difficulty": "medium"
    },
    {
      "id": "q2",
      "domain": 1,
      "question": "データサイエンティストがNLPモデル用のテキストデータを処理する必要があります。テキストを数値ベクトルに変換する前処理ステップはどれですか？",
      "options": {
        "A": "トークン化とエンベディング",
        "B": "ワンホットエンコーディング",
        "C": "標準スケーリング",
        "D": "ビニング"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "トークン化とエンベディングはテキストを数値表現に変換します：\n- トークン化でテキストをトークンに分割\n- エンベディングでトークンを密なベクトルにマッピング\n- セマンティックな関係を捉える\n- Word2Vec、BERTなどの事前学習済みエンベディングが利用可能\n\nワンホット (B)はカテゴリ特徴量用です。標準スケーリング (C)は数値を正規化します。ビニング (D)は連続値を離散化します。",
      "difficulty": "medium"
    },
    {
      "id": "q3",
      "domain": 1,
      "question": "機械学習チームがラベリングコストを削減するためにアクティブラーニングを使用したいと考えています。アクティブラーニングの重要な原則は何ですか？",
      "options": {
        "A": "モデルが人間のラベリング用に最も情報量の多いサンプルを選択する",
        "B": "モデルがすべてのデータを自動的にラベル付けする",
        "C": "すべてのデータがランダムにラベル付けされる",
        "D": "ラベリングは不要"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "アクティブラーニングは戦略的にラベリング用のサンプルを選択します：\n- モデルが不確実または情報量の多いサンプルを特定\n- 人間は選択されたサンプルのみをラベル付け\n- 全体的なラベリング作業を削減\n- SageMaker Ground Truthはアクティブラーニングをサポート\n\n自動ラベリング (B)にはエラーがある可能性があります。ランダム (C)は非効率的です。ラベリングなし (D)は教師なし学習です。",
      "difficulty": "medium"
    },
    {
      "id": "q4",
      "domain": 1,
      "question": "データエンジニアがトレーニングに使用される特徴量と推論に使用される特徴量が一致することを確認する必要があります。この問題は何と呼ばれますか？",
      "options": {
        "A": "トレーニング-サービングスキュー",
        "B": "データリーケージ",
        "C": "コンセプトドリフト",
        "D": "モデル劣化"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "トレーニング-サービングスキューは、トレーニングと推論の間で特徴量が異なる場合に発生します：\n- 異なる前処理ロジック\n- 異なるデータソース\n- Feature Storeがこれを防ぐのに役立つ\n- 同じ変換コードを使用する\n\nデータリーケージ (B)はテストセットからの情報です。コンセプトドリフト (C)はパターンの変化です。モデル劣化 (D)はパフォーマンスの低下です。",
      "difficulty": "medium"
    },
    {
      "id": "q5",
      "domain": 1,
      "question": "企業がMLトレーニング用に複数のテーブルから特徴量を集約する必要があります。最もよく使用されるSQL操作はどれですか？",
      "options": {
        "A": "テーブルを結合するJOIN操作",
        "B": "データを削除するDELETE操作",
        "C": "テーブルをクリアするTRUNCATE操作",
        "D": "権限を設定するGRANT操作"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "JOIN操作は複数のテーブルからデータを結合します：\n- 顧客、トランザクション、製品データをマージ\n- 包括的な特徴量セットを作成\n- 様々な結合タイプ（INNER、LEFTなど）をサポート\n- 特徴量エンジニアリングの基盤\n\nDELETE (B)はデータを削除します。TRUNCATE (C)はテーブルをクリアします。GRANT (D)は権限を管理します。",
      "difficulty": "medium"
    },
    {
      "id": "q6",
      "domain": 1,
      "question": "データサイエンティストが順序が重要な順序カテゴリ変数（例：低、中、高）をエンコードする必要があります。どのエンコーディングを使用すべきですか？",
      "options": {
        "A": "順序を保持する整数エンコーディング",
        "B": "ワンホットエンコーディング",
        "C": "ターゲットエンコーディング",
        "D": "バイナリエンコーディング"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "整数エンコーディングは順序関係を保持します：\n- 順序付けられた整数を割り当てる（低=1、中=2、高=3）\n- 自然な順序を維持\n- 順序を使用するアルゴリズムに適している\n- 順序データにはワンホットより単純\n\nワンホット (B)は順序情報を失います。ターゲット (C)はターゲット変数を使用します。バイナリ (D)は高カーディナリティ用です。",
      "difficulty": "medium"
    },
    {
      "id": "q7",
      "domain": 1,
      "question": "機械学習エンジニアがクラス分布を維持しながら大規模データセットをサンプリングする必要があります。どのサンプリング手法を使用すべきですか？",
      "options": {
        "A": "層化サンプリング",
        "B": "ランダムサンプリング",
        "C": "系統的サンプリング",
        "D": "クラスターサンプリング"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "層化サンプリングはクラス比率を維持します：\n- 各クラスから比例してサンプリング\n- 元のクラス分布を保持\n- 不均衡なデータセットに重要\n- 代表的なサンプルを確保\n\nランダム (B)は比率を保持しない可能性があります。系統的 (C)は固定間隔を使用します。クラスター (D)はグループ全体をサンプリングします。",
      "difficulty": "medium"
    },
    {
      "id": "q8",
      "domain": 1,
      "question": "データサイエンティストが2つのカテゴリ変数間の相互作用特徴量を作成する必要があります。どの手法を使用すべきですか？",
      "options": {
        "A": "特徴量クロッシング",
        "B": "特徴量スケーリング",
        "C": "特徴量選択",
        "D": "特徴量抽出"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "特徴量クロッシングは相互作用特徴量を作成します：\n- カテゴリ特徴量を組み合わせる\n- 組み合わせを表す新しい特徴量を作成\n- 例：city + device_type = city_device\n- 相互作用効果を捉える\n\nスケーリング (B)は値を正規化します。選択 (C)は特徴量を選びます。抽出 (D)は次元を削減します。",
      "difficulty": "medium"
    },
    {
      "id": "q9",
      "domain": 1,
      "question": "企業がS3に生データを保存しており、ML用に変換する必要があります。ビジュアルでノーコードのソリューションを求めています。どのサービスを使用すべきですか？",
      "options": {
        "A": "AWS Glue DataBrew",
        "B": "Amazon EMR",
        "C": "AWS Lambda",
        "D": "Amazon EC2"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "AWS Glue DataBrewはノーコードのデータ準備ツールです：\n- データ変換用のビジュアルインターフェース\n- 250以上の組み込み変換\n- データプロファイリング機能\n- MLトレーニング用にS3に出力\n\nEMR (B)はコーディングが必要です。Lambda (C)はコードが必要です。EC2 (D)はセットアップとコーディングが必要です。",
      "difficulty": "medium"
    },
    {
      "id": "q10",
      "domain": 1,
      "question": "データエンジニアがデータセットから重複レコードを検出して削除する必要があります。大規模データセットに最も効果的なアプローチはどれですか？",
      "options": {
        "A": "重複排除ロジックを持つSparkまたはGlueを使用",
        "B": "すべてのレコードを手動でレビュー",
        "C": "すべての重複を保持",
        "D": "ランダムサンプリング"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "Spark/Glueはスケーラブルな重複排除を提供します：\n- 大規模データセットを効率的に処理\n- groupByと集計関数を使用\n- 重複排除キーを定義\n- 自動化され再現可能\n\n手動レビュー (B)はスケールしません。重複を保持 (C)はトレーニングに影響します。ランダムサンプリング (D)は重複を削除しません。",
      "difficulty": "medium"
    },
    {
      "id": "q11",
      "domain": 2,
      "question": "データサイエンティストが協調フィルタリングを使用してレコメンデーションシステムを構築しています。この目的で設計されたSageMaker組み込みアルゴリズムはどれですか？",
      "options": {
        "A": "Factorization Machines",
        "B": "XGBoost",
        "C": "Linear Learner",
        "D": "K-Means"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "Factorization Machinesはレコメンデーションシステムに最適です：\n- ユーザー-アイテムの相互作用を捉える\n- スパースデータを適切に処理\n- クリック予測とレコメンデーションをサポート\n- SageMaker用に最適化\n\nXGBoost (B)は勾配ブースティングです。Linear Learner (C)は線形モデル用です。K-Means (D)はクラスタリング用です。",
      "difficulty": "medium"
    },
    {
      "id": "q12",
      "domain": 2,
      "question": "機械学習チームが特定のドメイン向けに事前学習済み大規模言語モデルをファインチューニングする必要があります。このプロセスは何と呼ばれますか？",
      "options": {
        "A": "転移学習/ファインチューニング",
        "B": "ゼロからのトレーニング",
        "C": "アンサンブル学習",
        "D": "強化学習"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "転移学習/ファインチューニングは事前学習済みモデルを適応させます：\n- 事前学習済みモデルの重みから開始\n- ドメイン固有のデータで重みを更新\n- ゼロからのトレーニングより少ないデータで済む\n- 収束が速い\n\nゼロから (B)は事前学習を無視します。アンサンブル (C)はモデルを組み合わせます。強化学習 (D)は報酬を使用します。",
      "difficulty": "medium"
    },
    {
      "id": "q13",
      "domain": 2,
      "question": "データサイエンティストが過学習を防ぐためにアーリーストッピングを使用したいと考えています。アーリーストッピングは何を監視しますか？",
      "options": {
        "A": "検証損失またはメトリクス",
        "B": "トレーニング時間",
        "C": "モデルサイズ",
        "D": "特徴量の数"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "アーリーストッピングは検証パフォーマンスを監視します：\n- 検証メトリクスが改善しなくなったら停止\n- トレーニングデータへの過学習を防ぐ\n- 許容度のためにpatienceパラメータを使用\n- ニューラルネットワークのトレーニングで一般的\n\nトレーニング時間 (B)、モデルサイズ (C)、特徴量 (D)は過学習を示しません。",
      "difficulty": "medium"
    },
    {
      "id": "q14",
      "domain": 2,
      "question": "企業がMLモデルが特定の予測を行う理由を顧客に説明したいと考えています。人間が解釈可能な説明を提供する手法はどれですか？",
      "options": {
        "A": "SHAP (SHapley Additive exPlanations)",
        "B": "勾配降下法",
        "C": "バッチ正規化",
        "D": "ドロップアウト"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "SHAPは解釈可能な特徴量の寄与を提供します：\n- ゲーム理論に基づく\n- 各特徴量の予測への寄与を示す\n- モデルに依存しない\n- SageMaker ClarifyはSHAPを使用\n\n勾配降下法 (B)は最適化です。バッチ正規化 (C)は活性化を正規化します。ドロップアウト (D)は過学習を防ぎます。",
      "difficulty": "medium"
    },
    {
      "id": "q15",
      "domain": 2,
      "question": "機械学習エンジニアが大規模ニューラルネットワークのモデルトレーニング時間を短縮する必要があります。複数のGPU間でトレーニングを並列化する手法はどれですか？",
      "options": {
        "A": "データ並列処理",
        "B": "アーリーストッピング",
        "C": "ドロップアウト",
        "D": "特徴量選択"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "データ並列処理はGPU間でトレーニングを分散します：\n- GPU間でデータバッチを分割\n- 各GPUが勾配を計算\n- 勾配が同期される\n- ほぼ線形のスピードアップが可能\n\nアーリーストッピング (B)はトレーニングを停止します。ドロップアウト (C)は正則化です。特徴量選択 (D)は特徴量を削減します。",
      "difficulty": "medium"
    },
    {
      "id": "q16",
      "domain": 2,
      "question": "データサイエンティストがマルチクラス分類問題の損失関数を選択する必要があります。適切な損失関数はどれですか？",
      "options": {
        "A": "カテゴリカルクロスエントロピー",
        "B": "平均二乗誤差",
        "C": "平均絶対誤差",
        "D": "Huber損失"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "カテゴリカルクロスエントロピーはマルチクラス分類の標準です：\n- 予測と実際のクラス確率の差を測定\n- softmax活性化と連携\n- 自信を持った間違った予測を大きくペナライズ\n- ニューラルネットワーク分類の標準\n\nMSE (B)、MAE (C)、Huber (D)は回帰用です。",
      "difficulty": "medium"
    },
    {
      "id": "q17",
      "domain": 2,
      "question": "機械学習チームが精度を向上させるために複数のモデルの予測を組み合わせたいと考えています。この手法は何と呼ばれますか？",
      "options": {
        "A": "アンサンブル学習",
        "B": "転移学習",
        "C": "アクティブラーニング",
        "D": "強化学習"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "アンサンブル学習は複数のモデルを組み合わせます：\n- 投票、平均化、またはスタッキングで予測\n- 分散を減らし精度を向上\n- 一般的な手法：バギング、ブースティング\n- 単一モデルを上回ることが多い\n\n転移 (B)は事前学習済みモデルを使用します。アクティブ (C)はラベリング用のサンプルを選択します。強化学習 (D)は報酬を使用します。",
      "difficulty": "medium"
    },
    {
      "id": "q18",
      "domain": 2,
      "question": "データサイエンティストがNLPモデル用に可変長のシーケンスを処理する必要があります。シーケンシャルデータ用に特別に設計されたニューラルネットワークアーキテクチャはどれですか？",
      "options": {
        "A": "リカレントニューラルネットワーク（RNN）/LSTM",
        "B": "畳み込みニューラルネットワーク（CNN）",
        "C": "全結合ネットワーク",
        "D": "オートエンコーダー"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "RNN/LSTMアーキテクチャはシーケンシャルデータを処理します：\n- 可変長のシーケンスを処理\n- 以前の入力のメモリを維持\n- LSTMは長期依存関係を処理\n- トランスフォーマー以前のNLPの標準\n\nCNN (B)は画像/ローカルパターン用です。全結合 (C)は固定入力が必要です。オートエンコーダー (D)は圧縮用です。",
      "difficulty": "medium"
    },
    {
      "id": "q19",
      "domain": 2,
      "question": "機械学習エンジニアが過学習を防ぐためにL2正則化を使用する必要があります。L2正則化は損失関数に何を追加しますか？",
      "options": {
        "A": "重みの二乗和",
        "B": "重みの絶対値の和",
        "C": "非ゼロの重みの数",
        "D": "トレーニング時間"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "L2正則化は二乗重みペナルティを追加します：\n- lambda * sum(weights^2)を損失に追加\n- より小さい重みを促進\n- 過学習を防ぐ\n- 重み減衰とも呼ばれる\n\n絶対値の和 (B)はL1正則化です。非ゼロカウント (C)はL0です。トレーニング時間 (D)はペナルティではありません。",
      "difficulty": "medium"
    },
    {
      "id": "q20",
      "domain": 2,
      "question": "データサイエンティストが回帰モデルを評価する必要があります。平均予測誤差を測定するメトリクスはどれですか？",
      "options": {
        "A": "平均絶対誤差（MAE）",
        "B": "精度",
        "C": "適合率",
        "D": "再現率"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "MAEは平均絶対予測誤差を測定します：\n- |予測 - 実際|の平均\n- ターゲットと同じ単位で解釈可能\n- 外れ値に対してロバスト\n- 一般的な回帰メトリクス\n\n精度 (B)、適合率 (C)、再現率 (D)は分類メトリクスです。",
      "difficulty": "medium"
    },
    {
      "id": "q21",
      "domain": 3,
      "question": "企業がバックグラウンドでリクエストを処理し、完了時に通知するMLモデルをデプロイする必要があります。適切なデプロイパターンはどれですか？",
      "options": {
        "A": "非同期推論",
        "B": "同期リアルタイム推論",
        "C": "バッチ変換",
        "D": "エッジデプロイメント"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "非同期推論はバックグラウンド処理を処理します：\n- リクエストはすぐにジョブIDを返す\n- 完了時に結果を配信\n- 大きなペイロードをサポート\n- 可変レイテンシーのワークロードに適している\n\n同期 (B)は応答を待ちます。バッチ (C)はスケジュールされたジョブ用です。エッジ (D)はデバイス上で実行します。",
      "difficulty": "medium"
    },
    {
      "id": "q22",
      "domain": 3,
      "question": "機械学習エンジニアが新しいモデルをデプロイせずにインフラストラクチャの変更をテストしたいと考えています。これを可能にするSageMaker機能はどれですか？",
      "options": {
        "A": "推論コンポーネントの更新",
        "B": "モデルの再トレーニング",
        "C": "データ前処理",
        "D": "特徴量エンジニアリング"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "推論コンポーネントはインフラストラクチャを独立して更新できます：\n- モデルをインフラストラクチャ構成から分離\n- モデルを変更せずにインスタンスタイプを更新\n- コンポーネントを独立してスケール\n- デプロイの複雑さを軽減\n\n再トレーニング (B)はモデルを変更します。前処理 (C)と特徴量エンジニアリング (D)はデータ準備です。",
      "difficulty": "medium"
    },
    {
      "id": "q23",
      "domain": 3,
      "question": "企業がコードがリポジトリにプッシュされたときにMLパイプラインが自動的に実行されることを確認したいと考えています。これを可能にする統合はどれですか？",
      "options": {
        "A": "SageMakerパイプライントリガーを持つCodePipeline",
        "B": "手動パイプライン実行",
        "C": "スケジュールされたCloudWatchイベントのみ",
        "D": "直接S3アップロード"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "CodePipeline統合はML用のCI/CDを可能にします：\n- コードコミットでトリガー\n- SageMakerパイプラインを自動的に実行\n- テストと検証ステージを含む\n- エンドツーエンドの自動化\n\n手動実行 (B)は人間のアクションが必要です。スケジュール (C)は時間ベースです。S3アップロード (D)はデータのみです。",
      "difficulty": "medium"
    },
    {
      "id": "q24",
      "domain": 3,
      "question": "機械学習チームが異なるモデル構成で異なる顧客にサービスを提供するモデルをデプロイする必要があります。最適なアプローチはどれですか？",
      "options": {
        "A": "顧客固有のモデルを持つマルチモデルエンドポイント",
        "B": "すべての顧客に単一モデル",
        "C": "手動モデル切り替え",
        "D": "顧客ごとに異なるAWSアカウント"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "マルチモデルエンドポイントは顧客固有のモデルをサポートします：\n- 複数のモデルバリアントをホスト\n- リクエストを適切なモデルにルーティング\n- コスト削減のための共有インフラストラクチャ\n- 動的モデルロード\n\n単一モデル (B)はカスタマイズがありません。手動切り替え (C)は遅いです。別アカウント (D)は複雑です。",
      "difficulty": "medium"
    },
    {
      "id": "q25",
      "domain": 3,
      "question": "企業がスケジュールに従って推論ジョブを実行し、夜間に蓄積されたデータを処理する必要があります。最適なSageMaker機能はどれですか？",
      "options": {
        "A": "EventBridgeスケジューリングを持つSageMakerバッチ変換",
        "B": "リアルタイムエンドポイント",
        "C": "サーバーレス推論",
        "D": "非同期推論"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "スケジューリングを持つバッチ変換は定期的なバッチジョブに最適です：\n- EventBridgeがスケジュールされた時間にトリガー\n- バッチ変換が蓄積されたデータを処理\n- ジョブ間でインフラストラクチャが実行されない\n- 定期的なワークロードにコスト効果的\n\nリアルタイム (B)は即座の応答用です。サーバーレス (C)は可変負荷用です。非同期 (D)はリクエストベースです。",
      "difficulty": "medium"
    },
    {
      "id": "q26",
      "domain": 3,
      "question": "機械学習エンジニアが本番デプロイメント用のモデルバージョニングを実装する必要があります。この機能を提供するサービスはどれですか？",
      "options": {
        "A": "SageMaker Model Registry",
        "B": "Amazon S3",
        "C": "AWS CodeCommit",
        "D": "Amazon ECR"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "Model Registryは包括的なモデルバージョニングを提供します：\n- モデルバージョンをカタログ化\n- メタデータとメトリクスを追跡\n- 承認ワークフローを管理\n- アーティファクトとリネージにリンク\n\nS3 (B)はファイルを保存します。CodeCommit (C)はコードをバージョン管理します。ECR (D)はコンテナイメージを保存します。",
      "difficulty": "medium"
    },
    {
      "id": "q27",
      "domain": 3,
      "question": "企業がサーバーレス推論エンドポイントのコールドスタートレイテンシーを削減したいと考えています。これに役立つ構成はどれですか？",
      "options": {
        "A": "プロビジョンド同時実行",
        "B": "より大きなメモリ割り当てのみ",
        "C": "より小さなモデルサイズのみ",
        "D": "VPC構成"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "プロビジョンド同時実行はインスタンスをウォームに保ちます：\n- 事前初期化された実行環境\n- コールドスタートレイテンシーを排除\n- 保証されたキャパシティ\n- 高コストだが一貫したパフォーマンス\n\nメモリ (B)は実行速度に影響します。モデルサイズ (C)はロード時間に影響します。VPC (D)はレイテンシーを追加する可能性があります。",
      "difficulty": "medium"
    },
    {
      "id": "q28",
      "domain": 3,
      "question": "機械学習チームがデバッグのためにすべての推論リクエストとレスポンスをログに記録する必要があります。これを提供するSageMaker機能はどれですか？",
      "options": {
        "A": "エンドポイントのデータキャプチャ",
        "B": "CloudWatch Logsのみ",
        "C": "S3アクセスログ",
        "D": "CloudTrail"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "データキャプチャは推論リクエスト/レスポンスデータをログに記録します：\n- 入力と出力データをキャプチャ\n- 分析用にS3に保存\n- 監視とデバッグに使用\n- Model Monitor統合をサポート\n\nCloudWatch (B)ログは運用ログです。S3ログ (C)はアクセスを追跡します。CloudTrail (D)はAPI呼び出しをログに記録します。",
      "difficulty": "medium"
    },
    {
      "id": "q29",
      "domain": 3,
      "question": "企業がオンプレミスのデータセンターにあるAWS OutpostsにMLモデルをデプロイする必要があります。これを可能にするサービスはどれですか？",
      "options": {
        "A": "SageMaker Edge Manager",
        "B": "SageMakerリアルタイム推論のみ",
        "C": "AWS Lambda",
        "D": "Amazon EC2"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "SageMaker Edge Managerはエッジとオンプレミスのデプロイメントをサポートします：\n- Outpostsにモデルをデプロイ\n- エッジデプロイメントを一元管理\n- エッジモデルのパフォーマンスを監視\n- IoT Greengrassと連携\n\nリアルタイム推論 (B)はクラウドベースです。Lambda (C)はクラウドサーバーレスです。EC2 (D)は手動管理が必要です。",
      "difficulty": "medium"
    },
    {
      "id": "q30",
      "domain": 3,
      "question": "機械学習エンジニアがモデルデプロイメントのロールバック機能を実装する必要があります。最適なアプローチはどれですか？",
      "options": {
        "A": "ブルーグリーンデプロイメントを持つModel Registryバージョンを使用",
        "B": "デプロイ後に古いモデルを削除",
        "C": "手動モデルファイル管理",
        "D": "最新モデルのみを保持"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "ブルーグリーンを持つModel Registryは安全なロールバックを可能にします：\n- 以前のモデルバージョンを保持\n- ブルーグリーンで即座に切り替え可能\n- 問題がある場合は以前のバージョンにロールバック\n- デプロイメントパイプラインで自動化\n\n古いモデルの削除 (B)はロールバックを防ぎます。手動 (C)はエラーが発生しやすいです。最新のみ (D)は履歴がありません。",
      "difficulty": "medium"
    },
    {
      "id": "q31",
      "domain": 4,
      "question": "機械学習チームがモデルは平均的には良好に機能するが、特定の顧客セグメントでは不良であることに気付きました。どのタイプの分析を実行すべきですか？",
      "options": {
        "A": "スライスベースの評価/公平性分析",
        "B": "全体的な精度チェック",
        "C": "トレーニングデータのレビューのみ",
        "D": "インフラストラクチャ監視"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "スライスベースの評価はセグメント固有の問題を明らかにします：\n- データサブグループ間でパフォーマンスを分析\n- パフォーマンスが低いセグメントを特定\n- 公平性の問題をチェック\n- SageMaker Clarifyがこれをサポート\n\n全体的な精度 (B)はセグメントの問題を隠します。トレーニングデータ (C)は1つの側面です。インフラストラクチャ (D)はリソースを監視します。",
      "difficulty": "medium"
    },
    {
      "id": "q32",
      "domain": 4,
      "question": "企業のMLモデルが来月廃止される予定の特徴量に基づいて予測を行っています。何をすべきですか？",
      "options": {
        "A": "廃止前にその特徴量なしでモデルを再トレーニング",
        "B": "特徴量が廃止されるまで待つ",
        "C": "廃止を無視する",
        "D": "古いモデルを使い続ける"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "プロアクティブな再トレーニングはモデルの障害を防ぎます：\n- 廃止される特徴量なしで新しいモデルをトレーニング\n- デプロイ前にパフォーマンスを検証\n- 特徴量が削除される前にデプロイ\n- 本番の障害を回避\n\n待つ (B)は障害を引き起こします。無視 (C)はエラーのリスクがあります。古いモデル (D)は壊れます。",
      "difficulty": "medium"
    },
    {
      "id": "q33",
      "domain": 4,
      "question": "機械学習エンジニアがトレーニングからデプロイメントまでのモデルのエンドツーエンドの旅程を追跡する必要があります。これを説明する概念はどれですか？",
      "options": {
        "A": "モデルリネージ",
        "B": "モデル精度",
        "C": "モデルレイテンシー",
        "D": "モデルサイズ"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "モデルリネージは完全なモデルの旅程を追跡します：\n- トレーニングに使用されたデータソース\n- コードとパラメータ\n- トレーニングジョブの詳細\n- デプロイメント履歴\n\n精度 (B)はパフォーマンスを測定します。レイテンシー (C)は速度を測定します。サイズ (D)はストレージを測定します。",
      "difficulty": "medium"
    },
    {
      "id": "q34",
      "domain": 4,
      "question": "企業がML運用がベストプラクティスに従っていることを確認する必要があります。MLシステムのガイダンスを提供するフレームワークはどれですか？",
      "options": {
        "A": "AWS Well-Architected Framework Machine Learning Lens",
        "B": "一般的なAWSドキュメントのみ",
        "C": "サードパーティフレームワークのみ",
        "D": "内部ガイドラインのみ"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "ML Lensは構造化されたMLベストプラクティスを提供します：\n- MLワークロードに適用された6つの柱\n- MLシステムの設計原則\n- セキュリティ、信頼性のベストプラクティス\n- レビューの質問とガイダンス\n\n一般ドキュメント (B)はMLに焦点を当てていません。サードパーティ (C)はAWSと整合しない可能性があります。内部 (D)は不完全な可能性があります。",
      "difficulty": "medium"
    },
    {
      "id": "q35",
      "domain": 4,
      "question": "デプロイされたモデルの予測が特定のグループに対してますます偏りを持つようになっています。これを検出する監視はどれですか？",
      "options": {
        "A": "SageMaker Clarifyを使用したバイアスドリフト監視",
        "B": "CPU使用率監視",
        "C": "ネットワークスループット監視",
        "D": "ストレージ容量監視"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "バイアスドリフト監視は公平性の変化を検出します：\n- バイアスメトリクスの継続的な監視\n- 現在をベースラインの公平性と比較\n- 重大なドリフトでアラート\n- コンプライアンス要件をサポート\n\nCPU (B)、ネットワーク (C)、ストレージ (D)はインフラストラクチャメトリクスです。",
      "difficulty": "medium"
    },
    {
      "id": "q36",
      "domain": 4,
      "question": "機械学習チームがパフォーマンスSLAを維持しながらモデルサービングコストを最適化する必要があります。何を分析すべきですか？",
      "options": {
        "A": "使用率メトリクスに基づくインスタンスの適正化",
        "B": "常に最大のインスタンスを使用",
        "C": "常に最小のインスタンスを使用",
        "D": "コスト考慮を無視"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "適正化はコスト-パフォーマンスのバランスを最適化します：\n- CPU、メモリ、GPU使用率を分析\n- インスタンスサイズを実際のニーズに合わせる\n- オートスケーリングポリシーを検討\n- SageMaker推論レコメンデーションを使用\n\n最大 (B)は無駄です。最小 (C)はパフォーマンスを損なう可能性があります。コストを無視 (D)は無駄です。",
      "difficulty": "medium"
    },
    {
      "id": "q37",
      "domain": 4,
      "question": "企業が低信頼度のモデル予測に対して人間のレビューを実装したいと考えています。これをサポートするアプローチはどれですか？",
      "options": {
        "A": "人間のレビューワークフロー用のSageMaker Augmented AI（A2I）",
        "B": "すべての予測の自動承認",
        "C": "すべての低信頼度予測を拒否",
        "D": "すべての予測でモデルを再トレーニング"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "Augmented AIはヒューマンインザループワークフローを可能にします：\n- 低信頼度の予測を人間にルーティング\n- 信頼度しきい値を定義\n- Amazon Mechanical Turkまたはプライベートワークフォースと統合\n- 時間とともにモデル品質を向上\n\n自動承認 (B)は不確実性を無視します。すべて拒否 (C)は予測を失います。再トレーニング (D)は非現実的です。",
      "difficulty": "medium"
    },
    {
      "id": "q38",
      "domain": 4,
      "question": "機械学習エンジニアが規制コンプライアンスのためにモデルの動作を文書化する必要があります。何を含めるべきですか？",
      "options": {
        "A": "意図された使用、制限、パフォーマンスメトリクスを含むモデルカード",
        "B": "モデルファイルのみ",
        "C": "トレーニングデータのみ",
        "D": "デプロイメントスクリプトのみ"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "モデルカードは包括的なドキュメントを提供します：\n- 意図された使用ケース\n- 制限と倫理的考慮事項\n- セグメント間のパフォーマンスメトリクス\n- トレーニングデータの特性\n\nモデルファイル (B)、トレーニングデータ (C)、スクリプト (D)だけではコンプライアンスには不十分です。",
      "difficulty": "medium"
    },
    {
      "id": "q39",
      "domain": 4,
      "question": "企業がモデルが本番環境ではテストと異なるパフォーマンスを示すことを発見しました。最も可能性の高い原因は何ですか？",
      "options": {
        "A": "テストと本番データ間の分布シフト",
        "B": "両環境で同じデータ",
        "C": "同一のインフラストラクチャ",
        "D": "同じ前処理"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "分布シフトは本番-テスト間の差異を引き起こします：\n- 本番データがテストデータと異なる可能性\n- コンセプトドリフトまたはデータドリフト\n- 継続的な監視が必要\n- Model Monitorが検出を支援\n\n同じデータ (B)、インフラストラクチャ (C)、前処理 (D)は同様の結果を与えます。",
      "difficulty": "medium"
    },
    {
      "id": "q40",
      "domain": 4,
      "question": "機械学習チームがデータ品質が基準を満たす場合にのみモデル再トレーニングパイプラインがトリガーされることを確認したいと考えています。どのパターンを実装すべきですか？",
      "options": {
        "A": "パイプラインのデータ品質ゲート",
        "B": "データ品質に関係なく再トレーニング",
        "C": "手動データ品質チェックのみ",
        "D": "データ品質検証をスキップ"
      },
      "answer": "A",
      "answerType": "single",
      "explanation": "データ品質ゲートは有効なデータでのトレーニングを確保します：\n- トレーニング前にデータ品質をチェック\n- 品質が失敗した場合はパイプラインをブロック\n- AWS Glue Data Qualityまたはカスタムチェックを使用\n- 不良データでのトレーニングを防ぐ\n\n関係なく再トレーニング (B)は不良データを使用する可能性があります。手動のみ (C)はスケールしません。スキップ (D)は低品質モデルのリスクがあります。",
      "difficulty": "medium"
    }
  ]
}
