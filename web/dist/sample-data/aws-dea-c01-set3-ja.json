{
  "exam": {
    "id": "aws-dea-c01-set3-ja",
    "name": "AWS DEA-C01 模擬試験 #3",
    "code": "DEA-C01",
    "provider": "AWS",
    "language": "ja",
    "description": "AWSデータエンジニアアソシエイト認定試験模擬問題 - 第3セット",
    "totalQuestions": 40,
    "passingScore": 72,
    "examTime": 130,
    "domains": [
      {"id": 1, "name": "データ取り込みと変換", "weight": 34},
      {"id": 2, "name": "データストア管理", "weight": 26},
      {"id": 3, "name": "データ運用とサポート", "weight": 22},
      {"id": 4, "name": "データセキュリティとガバナンス", "weight": 18}
    ],
    "tags": ["AWS", "データエンジニアリング", "DEA", "認定試験"]
  },
  "questions": [
    {
      "id": "q1",
      "domain": 1,
      "question": "企業が複数のAWSアカウントのCloudTrailログをデータレイクに集約して分析する必要があります。最適なアーキテクチャは何ですか？",
      "options": {
        "A": "各アカウントで独立してCloudTrailを分析する",
        "B": "組織レベルのCloudTrailを使用し、すべてのログを収集するS3バケットを設定する",
        "C": "ログファイルを手動でコピーする",
        "D": "Lambdaでログを1つずつ読み取る"
      },
      "answer": "B",
      "explanation": "AWS Organizationsは組織レベルのCloudTrailをサポートし、すべてのメンバーアカウントのログを中央のS3バケットに自動送信でき、その後AthenaやGlueで分析できます。"
    },
    {
      "id": "q2",
      "domain": 1,
      "question": "Glue Studioビジュアルエディターを使用してETLジョブを作成する利点は何ですか？",
      "options": {
        "A": "生成されるコードのパフォーマンスが向上する",
        "B": "コードを書かずに複雑なETLフローを作成できる",
        "C": "より多くのデータソースをサポートする",
        "D": "コストが低い"
      },
      "answer": "B",
      "explanation": "Glue Studioはビジュアルドラッグアンドドロップインターフェースを提供し、ETLジョブを作成、実行、監視でき、プログラミングに詳しくないユーザーが迅速にデータパイプラインを構築するのに適しています。"
    },
    {
      "id": "q3",
      "domain": 1,
      "question": "Kinesis Data FirehoseがS3にデータを配信する際、配信時間ではなくビジネス日付でパーティショニングする必要があります。どのように実現しますか？",
      "options": {
        "A": "Firehoseのデフォルトパーティショニングを使用する",
        "B": "動的パーティショニング機能を使用してデータ内容からパーティションキーを抽出する",
        "C": "S3ライフサイクルポリシーでファイルを移動する",
        "D": "Lambdaで後処理してファイルを再編成する"
      },
      "answer": "B",
      "explanation": "Firehoseの動的パーティショニング機能により、データレコードからフィールド（ビジネス日付など）をパーティションキーとして抽出でき、デフォルトの配信時間パーティショニングではなくビジネスロジックでS3データを整理できます。"
    },
    {
      "id": "q4",
      "domain": 1,
      "question": "データソースがストリーミングとバッチの混合です。統一されたデータ処理アーキテクチャをどのように設計しますか？",
      "options": {
        "A": "2つの独立したパイプラインを別々に構築する",
        "B": "LambdaアーキテクチャまたはKappaアーキテクチャを使用する",
        "C": "バッチ処理のみを使用する",
        "D": "ストリーム処理のみを使用する"
      },
      "answer": "B",
      "explanation": "Lambdaアーキテクチャはバッチ処理層とスピード層を組み合わせて異なる要件を処理します。Kappaアーキテクチャはストリーム処理層のみに簡素化し、バッチデータをストリームの特殊ケースとして扱います。両方とも混合データを処理する成熟したパターンです。"
    },
    {
      "id": "q5",
      "domain": 1,
      "question": "AWS Glue ETLジョブが失敗し、エラーが\"Out of memory\"と表示されています。DPUを増やす以外に、どのような最適化方法がありますか？",
      "options": {
        "A": "出力パーティション数を減らす",
        "B": "pushDownPredicateを使用して読み取りデータ量を削減する",
        "C": "ジョブブックマークを無効にする",
        "D": "同期実行を使用する"
      },
      "answer": "B",
      "explanation": "pushDownPredicateは読み取り時にデータをフィルタリングでき、メモリ使用量を削減します。他の方法には、パーティション数を増やしてデータを分散する、collect()などのすべてのデータをdriverに収集する操作を避けることがあります。"
    },
    {
      "id": "q6",
      "domain": 2,
      "question": "地理空間データ（ユーザー位置、地図情報など）を保存してクエリする必要があります。最適なAWSサービスは何ですか？",
      "options": {
        "A": "Amazon DynamoDB",
        "B": "Amazon RDS for PostgreSQL with PostGIS",
        "C": "Amazon S3 + Athena",
        "D": "Amazon Redshift"
      },
      "answer": "B",
      "explanation": "PostgreSQLのPostGIS拡張機能は地理空間データ型とクエリ（距離計算、ジオフェンス、空間インデックスなど）を専門にサポートします。RDS for PostgreSQLはPostGISを完全にサポートしています。"
    },
    {
      "id": "q7",
      "domain": 2,
      "question": "データウェアハウスがマルチテナント分離をサポートする必要があり、各テナントは自分のデータのみを見ることができます。Redshiftでどのように実現しますか？",
      "options": {
        "A": "各テナントに異なるクラスターを使用する",
        "B": "テナントIDに基づいてフィルタリングする行レベルセキュリティ（RLS）ポリシーを使用する",
        "C": "異なるデータベースを使用する",
        "D": "アプリケーション層でフィルタリングする"
      },
      "answer": "B",
      "explanation": "Redshift RLSはユーザーのセッション変数（テナントIDなど）に基づいて自動的にデータをフィルタリングするポリシーを作成でき、クエリを変更せずに透過的なマルチテナント分離を実現します。"
    },
    {
      "id": "q8",
      "domain": 2,
      "question": "S3データレイクの履歴データがタイムトラベルクエリ（特定時点のデータスナップショットのクエリ）をサポートする必要があります。何を使用すべきですか？",
      "options": {
        "A": "S3 Versioning",
        "B": "Apache Icebergテーブルフォーマット",
        "C": "Glue Data Catalog履歴",
        "D": "S3 Object Lock"
      },
      "answer": "B",
      "explanation": "Apache Icebergはタイムトラベルクエリをサポートし、データをコピーせずに任意の時点のテーブルスナップショットをクエリできます。S3 Versioningはオブジェクトレベルであり、テーブルレベルの一貫したスナップショットをサポートしていません。"
    },
    {
      "id": "q9",
      "domain": 2,
      "question": "Athenaクエリ最適化：テーブルは日付でパーティショニングされていますが、クエリはまだすべてのパーティションをスキャンしています。原因は何ですか？",
      "options": {
        "A": "パーティションキーがWHERE句で使用されていない",
        "B": "Athenaはパーティショニングをサポートしていない",
        "C": "データファイルが大きすぎる",
        "D": "間違ったファイル形式を使用している"
      },
      "answer": "A",
      "explanation": "Athenaのパーティションプルーニングには、WHERE句でパーティションキーを明示的に使用する必要があります。クエリがパーティションキーをフィルタリングしていない、または関数でパーティションキーを処理している場合、パーティションプルーニングは実行できません。"
    },
    {
      "id": "q10",
      "domain": 2,
      "question": "DynamoDBテーブルの読み取りキャパシティユニット（RCU）が頻繁に制限に達しています。どのように最適化しますか？",
      "options": {
        "A": "WCUを増やす",
        "B": "DAXキャッシュレイヤーを有効にする",
        "C": "書き込み頻度を減らす",
        "D": "GSIを削除する"
      },
      "answer": "B",
      "explanation": "DynamoDB Accelerator（DAX）は完全マネージドのインメモリキャッシュで、読み取りレイテンシをミリ秒からマイクロ秒に削減し、ベーステーブルへの読み取りリクエストを減らしてRCU消費を削減します。"
    },
    {
      "id": "q11",
      "domain": 3,
      "question": "Glue Crawler実行後に作成されたテーブル名が命名規則に準拠していません。どのようにカスタマイズしますか？",
      "options": {
        "A": "Crawlerが自動生成するため変更できない",
        "B": "Crawler設定でテーブルプレフィックスを設定するか、Crawler後にLambdaをトリガーして修正する",
        "C": "テーブルを手動でリネームする",
        "D": "別のデータソースパスを使用する"
      },
      "answer": "B",
      "explanation": "Crawlerはテーブル名プレフィックスの設定をサポートしています。より複雑な命名要件には、EventBridgeでCrawler完了イベントを検出し、LambdaをトリガーしてAPIでテーブル名を変更できます。"
    },
    {
      "id": "q12",
      "domain": 3,
      "question": "Step Functionsの実行が25,000履歴イベントを超えて失敗しました。長時間実行されるワークフローをどのように処理しますか？",
      "options": {
        "A": "イベント制限を増やす",
        "B": "ネストされたワークフロー（Nested Workflows）またはContinue As Newパターンを使用する",
        "C": "Expressワークフローを使用する",
        "D": "状態数を減らす"
      },
      "answer": "B",
      "explanation": "ネストされたワークフローを使用して大きなワークフローをサブワークフローに分割するか、Continue As Newパターンを使用して新しい実行を開始して処理を継続し、単一実行のイベント制限を回避できます。"
    },
    {
      "id": "q13",
      "domain": 3,
      "question": "データパイプラインがバックプレッシャー（下流の処理速度が上流に追いつかない）状況を処理する必要があります。どのように処理しますか？",
      "options": {
        "A": "余分なデータを破棄する",
        "B": "バッファキューとしてSQSを使用する",
        "C": "下流の処理速度を上げる",
        "D": "上流の速度を下げる"
      },
      "answer": "B",
      "explanation": "SQSはバッファレイヤーとして機能し、上流が生成するメッセージを一時的に保存できます。下流のコンシューマーは自分のペースで処理し、SQSのメッセージ保持期間（最大14日）は十分なバッファ時間を提供します。"
    },
    {
      "id": "q14",
      "domain": 3,
      "question": "EMRクラスターでSparkジョブを実行し、ジョブ完了後に自動的にクラスターを終了してコストを節約する必要があります。どのように設定しますか？",
      "options": {
        "A": "クラスターを手動で終了する",
        "B": "EMR一時クラスター（Transient Cluster）モードを使用する",
        "C": "スケジュールされた終了を設定する",
        "D": "最小クラスターサイズを使用する"
      },
      "answer": "B",
      "explanation": "EMR一時クラスターはすべてのステップが完了した後に自動的に終了し、バッチ処理ジョブに非常に適しています。Step Functionsを使用してEMRステップをオーケストレーションし、完了後にクラスターを終了することもできます。"
    },
    {
      "id": "q15",
      "domain": 3,
      "question": "Glueジョブが実行時に設定パラメータを動的に取得する必要があります。ベストプラクティスは何ですか？",
      "options": {
        "A": "スクリプトにハードコードする",
        "B": "ジョブパラメータ（Job Parameters）またはSSM Parameter Storeを使用する",
        "C": "S3ファイルから読み取る",
        "D": "環境変数を使用する"
      },
      "answer": "B",
      "explanation": "Glueジョブパラメータは実行時に設定を渡すことができます。機密情報や一元管理が必要な設定には、SSM Parameter StoreまたはSecrets Managerの使用がより安全です。"
    },
    {
      "id": "q16",
      "domain": 4,
      "question": "データレイクに保存されているデータが7年間の保持要件を満たし、保持期間中は削除できないようにする必要があります。どのように実現しますか？",
      "options": {
        "A": "S3ライフサイクルルールを使用する",
        "B": "S3 Object Lockコンプライアンスモード（Compliance Mode）を使用する",
        "C": "IAMポリシーで削除を禁止する",
        "D": "定期的にバックアップする"
      },
      "answer": "B",
      "explanation": "S3 Object Lockコンプライアンスモードは、保持期間中は誰も（rootユーザーを含む）オブジェクトを削除または変更できないため、厳格なコンプライアンス保持要件を満たします。"
    },
    {
      "id": "q17",
      "domain": 4,
      "question": "データレイクでのデータ漏洩を検出して防止する必要があります。何を使用すべきですか？",
      "options": {
        "A": "S3アクセスログ",
        "B": "Amazon Macie + GuardDuty",
        "C": "CloudWatch Metrics",
        "D": "VPC Flow Logs"
      },
      "answer": "B",
      "explanation": "Macieは機密データを発見しアクセスパターンを監視でき、GuardDutyは異常なS3アクセス動作（大量ダウンロードなど）を検出できます。両者を組み合わせて包括的なデータ漏洩防止を提供します。"
    },
    {
      "id": "q18",
      "domain": 4,
      "question": "Redshiftクラスターが外部パートナーとデータを安全に共有する必要があります。どのように実現しますか？",
      "options": {
        "A": "データをエクスポートしてパートナーに送信する",
        "B": "Redshiftデータ共有（Data Sharing）を使用する",
        "C": "パブリックエンドポイントを作成する",
        "D": "クラスター認証情報を共有する"
      },
      "answer": "B",
      "explanation": "Redshift Data Sharingはクラスター間、アカウント間で安全にデータを共有でき、データをコピーする必要がありません。共有するデータベース、スキーマ、テーブルを制御でき、きめ細かな権限をサポートします。"
    },
    {
      "id": "q19",
      "domain": 4,
      "question": "データエンジニアが特定のLake Formationテーブルにアクセスできるユーザーを知る必要があります。どのようにクエリしますか？",
      "options": {
        "A": "S3バケットポリシーを確認する",
        "B": "Lake Formation権限APIまたはコンソールでテーブル権限を表示する",
        "C": "IAMポリシーを確認する",
        "D": "VPCセキュリティグループを確認する"
      },
      "answer": "B",
      "explanation": "Lake Formationは集中的な権限管理インターフェースを提供し、コンソールまたはAPIで特定のリソース（データベース、テーブル、列）の権限付与状況を表示できます。"
    },
    {
      "id": "q20",
      "domain": 4,
      "question": "VPC内のGlueジョブがパブリックAWS API（S3 APIなど）にアクセスする必要があります。どのように設定すべきですか？",
      "options": {
        "A": "Internet Gatewayを使用する",
        "B": "S3用のVPC Endpointを設定する",
        "C": "パブリックサブネットを使用する",
        "D": "VPC設定を無効にする"
      },
      "answer": "B",
      "explanation": "VPC EndpointによりVPC内のリソースがAWSサービスにプライベートにアクセスでき、トラフィックはインターネットを経由しません。S3 Gateway Endpointは無料で、GlueジョブがS3にアクセスするのに適しています。"
    },
    {
      "id": "q21",
      "domain": 1,
      "question": "OracleデータベースからS3に完全移行する必要があり、ストアドプロシージャとトリガーのロジックを含みます。どのように処理すべきですか？",
      "options": {
        "A": "DMSはストアドプロシージャを直接移行できる",
        "B": "DMSでデータを移行し、AWS SCTでストアドプロシージャロジックを変換する",
        "C": "すべてのロジックを手動で書き換える",
        "D": "ストアドプロシージャは移行できない"
      },
      "answer": "B",
      "explanation": "AWS Schema Conversion Tool（SCT）はストアドプロシージャ、トリガーなどのデータベースコードをターゲットプラットフォームに変換するのに役立ちます。DMSはデータ移行に、SCTはスキーマとコード変換に特化しています。"
    },
    {
      "id": "q22",
      "domain": 1,
      "question": "Glue ETLでビジネスルールに基づいて重複レコードをマージする必要があります。どの方法を使用すべきですか？",
      "options": {
        "A": "SQL DISTINCTを使用する",
        "B": "Glue FindMatches ML変換またはカスタム重複排除ロジックを使用する",
        "C": "ソースシステムで重複排除する",
        "D": "重複レコードを無視する"
      },
      "answer": "B",
      "explanation": "Glue FindMatchesは機械学習を使用して重複レコードを識別し、レコードが完全に同一でなくてもマッチングできます。単純な重複排除には、DataFrameのdropDuplicatesまたはカスタムルールを使用できます。"
    },
    {
      "id": "q23",
      "domain": 1,
      "question": "リアルタイムデータパイプラインにexactly-once処理セマンティクスが必要です。Kinesisを使用する場合、どのように保証しますか？",
      "options": {
        "A": "Kinesisはネイティブでexactly-onceをサポートする",
        "B": "トランザクショナル書き込みと冪等コンシューマー設計を使用する",
        "C": "リトライ回数を増やす",
        "D": "同期APIを使用する"
      },
      "answer": "B",
      "explanation": "Kinesisはat-least-onceセマンティクスを提供します。exactly-onceを実現するには、コンシューマー側で冪等性を実装（トランザクションIDを使用した重複排除など）し、ターゲットシステムへのトランザクショナル書き込みと組み合わせる必要があります。"
    },
    {
      "id": "q24",
      "domain": 2,
      "question": "Redshift RA3ノードタイプのDC2と比較した主な利点は何ですか？",
      "options": {
        "A": "より低いコスト",
        "B": "計算とストレージの分離、独立してスケーリング可能",
        "C": "より速いクエリ速度",
        "D": "より大きなメモリ"
      },
      "answer": "B",
      "explanation": "RA3ノードは計算とストレージを分離し、マネージドストレージ（RMS）を使用して、計算ノードを追加せずにストレージを独立してスケーリングでき、より柔軟で大容量データに対してより経済的です。"
    },
    {
      "id": "q25",
      "domain": 2,
      "question": "S3データレイクが複数のデータコンシューマーによる同じテーブルへの並行読み書きをサポートする必要があります。競合をどのように回避しますか？",
      "options": {
        "A": "S3 Object Lockを使用する",
        "B": "テーブルフォーマット（Iceberg/Delta/Hudi）の並行制御を使用する",
        "C": "単一ライターに制限する",
        "D": "S3 Versioningを使用する"
      },
      "answer": "B",
      "explanation": "Iceberg、Delta Lake、Hudiはすべて楽観的並行メカニズムを使用してACIDトランザクションと並行制御を提供し、複数のライターを処理してデータの一貫性を保証します。"
    },
    {
      "id": "q26",
      "domain": 2,
      "question": "データウェアハウスのディメンションテーブルが履歴変更を追跡する必要があります（SCD Type 2）。Redshiftでどのように実装しますか？",
      "options": {
        "A": "レコードを直接更新する",
        "B": "有効日付範囲と現在フラグ列を使用する",
        "C": "履歴テーブルのコピーを作成する",
        "D": "トリガーを使用する"
      },
      "answer": "B",
      "explanation": "SCD Type 2は有効開始日、終了日、現在レコードフラグを追加して履歴バージョンを保持します。更新時に現在のレコードを期限切れとしてマークし、新しいレコードを現在のバージョンとして挿入します。"
    },
    {
      "id": "q27",
      "domain": 3,
      "question": "Glueジョブがメモリ容量を超える大規模データセットを処理する必要があります。どの戦略を使用すべきですか？",
      "options": {
        "A": "メモリを増やす",
        "B": "パーティション処理とディスクへのスピル（Sparkのshuffle spill）を使用する",
        "C": "データ量を減らす",
        "D": "同期処理を使用する"
      },
      "answer": "B",
      "explanation": "Spark/Glueはメモリを超えるデータを自動的にディスクにスピルします。パーティション戦略を最適化してshuffleを減らし、G.2Xワーカータイプを使用してより多くのメモリとディスクスペースを取得できます。"
    },
    {
      "id": "q28",
      "domain": 3,
      "question": "データパイプラインが新しいETLロジックのA/Bテストをサポートする必要があります。どのように実現しますか？",
      "options": {
        "A": "本番パイプラインを直接置き換える",
        "B": "フィーチャーフラグを使用して新旧ロジックへのフローを制御し、並行実行して結果を比較する",
        "C": "開発環境でテストしてから直接本番に移行する",
        "D": "別のデータソースを使用する"
      },
      "answer": "B",
      "explanation": "フィーチャーフラグまたはトラフィック分割を使用して、一部のデータを新旧両方のパイプラインで同時に処理し、結果を比較して新しいロジックの正確性を検証してから、段階的に移行できます。"
    },
    {
      "id": "q29",
      "domain": 3,
      "question": "EMR上で実行されるSparkジョブが中間計算結果を共有する必要があります。最適なソリューションは何ですか？",
      "options": {
        "A": "ローカルディスクを使用する",
        "B": "EMRFS（S3）を使用してチェックポイントと中間結果を保存する",
        "C": "executorメモリを増やす",
        "D": "RDD cacheを使用する"
      },
      "answer": "B",
      "explanation": "EMRFSによりSparkジョブは永続ストレージとしてS3を使用でき、中間結果を複数のジョブで共有でき、ノード障害時にも失われません。"
    },
    {
      "id": "q30",
      "domain": 3,
      "question": "Glue Crawlerが検出したスキーマ変更を自動的に検出してチームに通知する必要があります。どのように実現しますか？",
      "options": {
        "A": "Data Catalogを手動で確認する",
        "B": "EventBridgeを使用してGlueイベントを検出し、SNS通知をトリガーする",
        "C": "比較スクリプトを定期的に実行する",
        "D": "CloudWatch Logsを使用する"
      },
      "answer": "B",
      "explanation": "GlueはCrawler状態変更やテーブル変更などのイベントをEventBridgeに送信します。これらのイベントに一致するルールを作成し、SNS通知、Lambda処理などをトリガーできます。"
    },
    {
      "id": "q31",
      "domain": 4,
      "question": "データレイク内のデータが作成後に変更されないこと（不変性）を確保する必要があります。どのように実現しますか？",
      "options": {
        "A": "IAMポリシーでPutObjectを制限する",
        "B": "S3 Object Lock WORM（Write Once Read Many）設定を使用する",
        "C": "読み取り専用バケットポリシーを使用する",
        "D": "S3 Glacierを使用する"
      },
      "answer": "B",
      "explanation": "S3 Object LockのWORM設定により、オブジェクトは書き込み後、保持期間が終了するまで変更または削除できないことが保証され、データの不変性の最も強力な保証です。"
    },
    {
      "id": "q32",
      "domain": 4,
      "question": "Lake Formationは既存のIAMポリシーとどのように連携しますか？",
      "options": {
        "A": "Lake FormationがIAMを完全に置き換える",
        "B": "アクセスにはIAMとLake Formation両方の権限を満たす必要がある",
        "C": "IAM権限のみを使用する",
        "D": "Lake FormationがIAMを自動的にオーバーライドする"
      },
      "answer": "B",
      "explanation": "Lake Formationは権限の重ね合わせモデルを採用しており、ユーザーはデータにアクセスするためにIAM権限（glue:GetTableなど）とLake Formation権限（そのテーブルへのSELECT）の両方を持っている必要があります。"
    },
    {
      "id": "q33",
      "domain": 1,
      "question": "MSK（Managed Streaming for Apache Kafka）を使用してデータを取り込む際、メッセージの順序をどのように確保しますか？",
      "options": {
        "A": "Kafkaは順序を保証しない",
        "B": "同じパーティション内でメッセージは順序を維持し、正しいパーティションキーを使用する",
        "C": "トランザクションを使用する",
        "D": "レプリカ数を増やす"
      },
      "answer": "B",
      "explanation": "Kafkaは単一パーティション内でメッセージの順序を保証します。適切なパーティションキー（ユーザーIDなど）を選択することで、関連するメッセージが同じパーティションに送信され、順序が維持されます。"
    },
    {
      "id": "q34",
      "domain": 1,
      "question": "Kinesis Data StreamsのデータをS3とRedshiftの両方に同時に送信する必要があります。どのように実現しますか？",
      "options": {
        "A": "2つの独立したKinesisストリームを作成する",
        "B": "同じKinesisストリームから読み取る2つのKinesis Data Firehose配信ストリームを使用する",
        "C": "コンシューマー内で2つのターゲットに書き込む",
        "D": "Lambdaを使用してデータをコピーする"
      },
      "answer": "B",
      "explanation": "同じKinesis Data Streamsから読み取る複数のFirehose配信ストリームを設定でき、各Firehoseが異なるターゲット（S3、Redshiftなど）を設定して、データのファンアウトを実現します。"
    },
    {
      "id": "q35",
      "domain": 2,
      "question": "Athenaクエリ結果を下流で使用するために特定のS3の場所にエクスポートする必要があります。どのように設定しますか？",
      "options": {
        "A": "Athenaが自動的に出力場所を選択する",
        "B": "CTASまたはINSERT INTOを使用して結果を指定されたテーブル/場所に書き込む",
        "C": "クエリ結果ファイルをコピーする",
        "D": "デフォルトの出力場所を使用する"
      },
      "answer": "B",
      "explanation": "CREATE TABLE AS SELECT（CTAS）またはINSERT INTOは、指定されたS3の場所にクエリ結果を書き込むことができ、形式、パーティショニング、圧縮を指定でき、下流の処理に便利です。"
    },
    {
      "id": "q36",
      "domain": 2,
      "question": "Redshift内のPIIデータに対して動的マスキングを行い、異なるユーザーが異なるマスキングレベルを見る必要があります。どのように実現しますか？",
      "options": {
        "A": "複数のマスキングテーブルを作成する",
        "B": "動的データマスキング（DDM）機能を使用する",
        "C": "アプリケーション層でマスキングする",
        "D": "ビューを使用する"
      },
      "answer": "B",
      "explanation": "Redshift Dynamic Data Masking（DDM）によりマスキングポリシーを定義でき、ユーザーロールに基づいて機密列に異なるマスキングルールを自動的に適用し、クエリの変更や複数のビューの作成が不要です。"
    },
    {
      "id": "q37",
      "domain": 3,
      "question": "データ品質ルールをETLパイプラインの一部として実行する必要があります。AWSネイティブソリューションは何ですか？",
      "options": {
        "A": "データを手動で確認する",
        "B": "AWS Glue Data Qualityを使用する",
        "C": "Lambdaでカスタム検証を行う",
        "D": "ターゲットデータベースで検証する"
      },
      "answer": "B",
      "explanation": "AWS Glue Data QualityによりGlueジョブ内でデータ品質ルール（完全性、一意性、範囲チェックなど）を定義でき、データを自動的に検証して品質レポートを生成します。"
    },
    {
      "id": "q38",
      "domain": 3,
      "question": "Glue ETLスクリプトのバージョン管理とCI/CDを実現する必要があります。どの方法を使用すべきですか？",
      "options": {
        "A": "Glueコンソールでスクリプトを編集する",
        "B": "スクリプトをGitに保存し、CodePipelineでデプロイする",
        "C": "S3バージョニングを使用する",
        "D": "スクリプトを手動でコピーする"
      },
      "answer": "B",
      "explanation": "GlueスクリプトとCloudFormation/CDKテンプレートをGitリポジトリに保存し、CodePipeline/CodeBuildを使用して自動テストとデプロイを実現することがETL CI/CDのベストプラクティスです。"
    },
    {
      "id": "q39",
      "domain": 4,
      "question": "ソースシステムからレポートまでの完全なデータリネージを追跡する必要があります。どのAWSサービスが役立ちますか？",
      "options": {
        "A": "CloudTrailのみ",
        "B": "Glue Data Catalog、Lake Formation、サードパーティリネージツールの組み合わせ",
        "C": "S3アクセスログ",
        "D": "VPC Flow Logs"
      },
      "answer": "B",
      "explanation": "Glue Data Catalogはメタデータを保存し、Lake Formationは権限を管理して基本的なリネージ情報を提供します。完全なエンドツーエンドのリネージには、通常Alation、CollibraなどのAWSパートナーツールと組み合わせる必要があります。"
    },
    {
      "id": "q40",
      "domain": 4,
      "question": "クロスアカウントデータ共有時に、受信側が特定のデータサブセットにのみアクセスできることをどのように確保しますか？",
      "options": {
        "A": "データセット全体を共有し、受信側でフィルタリングする",
        "B": "Lake Formationのきめ細かな権限を使用して共有するテーブル、列、行を制御する",
        "C": "データサブセットを受信側アカウントにコピーする",
        "D": "S3バケットポリシーを使用する"
      },
      "answer": "B",
      "explanation": "Lake Formationはクロスアカウント共有時のきめ細かな権限制御をサポートし、共有するデータベース、テーブル、列を正確に指定でき、行レベルフィルターを使用してデータ範囲を制限することもできます。"
    }
  ]
}
