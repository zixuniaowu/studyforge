# AWS Certified AI Practitioner (AIF-C01) 完全解答解説 - 第1セット

> 問題 + 正解 + 詳細解説を含む

---

## クイック解答一覧

| 問題 | 解答 | 問題 | 解答 | 問題 | 解答 | 問題 | 解答 | 問題 | 解答 |
|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Q1  | B | Q11 | A | Q21 | B | Q31 | B | Q41 | C |
| Q2  | A | Q12 | B | Q22 | B | Q32 | B | Q42 | B |
| Q3  | B | Q13 | B | Q23 | C | Q33 | B | Q43 | B |
| Q4  | B | Q14 | B | Q24 | B | Q34 | B | Q44 | B |
| Q5  | B | Q15 | B | Q25 | C | Q35 | B | Q45 | B |
| Q6  | C | Q16 | B | Q26 | A | Q36 | B | Q46 | B |
| Q7  | B | Q17 | B | Q27 | A | Q37 | C | Q47 | B |
| Q8  | C | Q18 | B | Q28 | B | Q38 | B | Q48 | B |
| Q9  | B | Q19 | B | Q29 | B | Q39 | B | Q49 | B |
| Q10 | C | Q20 | B | Q30 | B | Q40 | B | Q50 | B |

---

## Domain 1: AIとMLの基礎

---

### Q1
**問題**：ある企業が運用を最適化するために四半期ごとに予測を行っています。企業はこれらの予測にMLモデルを使用しています。AIプラクティショナーは、会社の利害関係者に透明性と説明可能性を提供するため、訓練されたMLモデルに関するレポートを作成しています。透明性と説明可能性の要件を満たすために、レポートに何を含めるべきですか？

A. モデル訓練コード
B. 部分依存プロット（PDPs）
C. 訓練サンプルデータ
D. モデル収束表

**✅ 解答：B - 部分依存プロット（PDPs）**

**解説**：部分依存プロット（Partial Dependence Plots、PDPs）は機械学習の説明可能性における重要なツールです：
- 特徴量が予測結果に与える限界効果を示す
- モデルの意思決定プロセスを理解するのに役立つ
- 非技術者の利害関係者に直感的な説明を提供

他の選択肢：コード(A)、サンプルデータ(C)、収束表(D)はモデルの動作を直接説明しません。

---

### Q2
**問題**：ある企業がヒト遺伝子を20のカテゴリに分類したいと考えています。企業はモデルの内部メカニズムが出力にどのように影響するかを記録するMLアルゴリズムを必要としています。これらの要件を満たすMLアルゴリズムはどれですか？

A. 決定木（Decision trees）
B. 線形回帰（Linear regression）
C. ロジスティック回帰（Logistic regression）
D. ニューラルネットワーク（Neural networks）

**✅ 解答：A - 決定木（Decision trees）**

**解説**：決定木は最も説明可能なMLアルゴリズムです：
- 意思決定プロセス全体を可視化できる
- 各ノードに明確なルールがある
- 完全な意思決定パスを追跡可能
- 「ホワイトボックス」モデルに属する

ニューラルネットワーク(D)は「ブラックボックス」であり、内部メカニズムの説明が困難です。線形/ロジスティック回帰は回帰または二値分類に使用され、20クラス分類には適していません。

---

### Q3
**問題**：ある企業が植物の葉の写真から植物の病気を予測する画像分類モデルを構築しました。企業はモデルが正しく分類した画像の数を評価したいと考えています。モデルのパフォーマンスを測定するためにどの評価指標を使用すべきですか？

A. R二乗スコア（R² score）
B. 正解率（Accuracy）
C. 二乗平均平方根誤差（RMSE）
D. 学習率（Learning rate）

**✅ 解答：B - 正解率（Accuracy）**

**解説**：
- **Accuracy（正解率）** = 正しい予測数 / 総予測数
- 「正しく分類した数」を直接測定
- R²とRMSEは回帰指標であり、分類には適していない
- Learning rateは訓練パラメータであり、評価指標ではない

---

### Q4
**問題**：ある企業がドメイン固有のモデルを使用しています。企業は新しいモデルをゼロから作成することを避け、新しい関連タスク用のモデルを作成するために事前訓練済みモデルを調整したいと考えています。これらの要件を満たすML戦略はどれですか？

A. エポック数を増やす
B. 転移学習（Transfer learning）を使用する
C. エポック数を減らす
D. 教師なし学習を使用する

**✅ 解答：B - 転移学習（Transfer learning）を使用する**

**解説**：転移学習は事前訓練済みモデルの知識を新しいタスクに転用します：
- ゼロから始める必要がない
- 既存の知識を活用
- 時間とリソースを節約
- 少量の新しいデータで新しいタスクに適応可能

---

### Q5
**問題**：機械学習において、モデルが訓練データでは良好に動作するが、新しいデータではパフォーマンスが悪い。この現象は何と呼ばれますか？

A. 未学習（Underfitting）
B. 過学習（Overfitting）
C. データドリフト（Data drift）
D. モデルバイアス（Model bias）

**✅ 解答：B - 過学習（Overfitting）**

**解説**：過学習の特徴：
- 訓練セットで良好なパフォーマンス
- 新しいデータ/テストセットでパフォーマンスが悪い
- モデルがパターンを学習する代わりに訓練データを「暗記」している

未学習(A)は両方でパフォーマンスが悪い。データドリフト(C)は本番データの分布変化。

---

### Q6
**問題**：以下のどの学習タイプがラベル付きデータを使用して訓練しますか？

A. 強化学習（Reinforcement Learning）
B. 教師なし学習（Unsupervised Learning）
C. 教師あり学習（Supervised Learning）
D. 自己教師あり学習（Self-supervised Learning）

**✅ 解答：C - 教師あり学習（Supervised Learning）**

**解説**：
- **教師あり学習**：ラベル付きデータ（入力-出力ペア）
- **教師なし学習**：ラベルなしデータ、パターンを発見
- **強化学習**：報酬信号を通じて学習
- **自己教師あり学習**：データ自体からラベルを生成

---

### Q7
**問題**：住宅価格を予測することは、どのタイプのML問題に属しますか？

A. 分類（Classification）
B. 回帰（Regression）
C. クラスタリング（Clustering）
D. 次元削減（Dimensionality Reduction）

**✅ 解答：B - 回帰（Regression）**

**解説**：
- **回帰**：連続的な数値を予測（価格、温度、売上）
- **分類**：離散的なカテゴリを予測（はい/いいえ、A/B/C）
- 住宅価格は連続的な数値 → 回帰問題

---

### Q8
**問題**：ある企業が顧客の特徴に基づいて顧客を異なるグループに分けたいと考えていますが、事前定義されたラベルがありません。どのML手法を使用すべきですか？

A. 教師あり学習 - 分類
B. 教師あり学習 - 回帰
C. 教師なし学習 - クラスタリング
D. 強化学習

**✅ 解答：C - 教師なし学習 - クラスタリング**

**解説**：事前定義されたラベルがなく、グループ分けが必要 → クラスタリング（教師なし学習）
- K-means
- 階層的クラスタリング
- DBSCAN

教師あり学習にはラベルが必要ですが、ここにはラベルがありません。

---

### Q9
**問題**：ニューラルネットワークにおいて「Epoch」とは何ですか？

A. モデルの層の数
B. 訓練データを完全に1回通過すること
C. ニューラルネットワークのタイプ
D. 学習率の値

**✅ 解答：B - 訓練データを完全に1回通過すること**

**解説**：
- **Epoch**：データセット全体を1回通過
- **Batch**：1回の更新に使用するサンプル数
- **Iteration**：1回のバッチ訓練

例：1000サンプル、batch=100の場合、1 epoch = 10 iterations

---

### Q10
**問題**：以下のうち、過学習を防ぐ方法ではないものはどれですか？

A. 訓練データを増やす
B. 正則化を使用する（Regularization）
C. モデルの複雑さを増やす
D. Dropoutを使用する

**✅ 解答：C - モデルの複雑さを増やす**

**解説**：モデルの複雑さを増やすと過学習が**悪化**します！

過学習を防ぐ方法：
- ✅ 訓練データを増やす
- ✅ 正則化（L1, L2）
- ✅ Dropout
- ✅ 早期停止（Early Stopping）
- ✅ データ拡張
- ❌ 複雑さを増やす（過学習を悪化させる）

---

## Domain 2: 生成AIの基礎

---

### Q11
**問題**：ある企業が事前訓練済みの大規模言語モデル（LLM）を使用して製品推薦チャットボットを構築しています。企業はLLMの出力を短く、特定の言語で書かれるようにする必要があります。LLMの応答品質を企業の期待に合わせるためのソリューションはどれですか？

A. プロンプトを調整する（Adjust the prompt）
B. 異なるサイズのLLMを選択する
C. temperatureを上げる
D. Top K値を上げる

**✅ 解答：A - プロンプトを調整する（Adjust the prompt）**

**解説**：プロンプトエンジニアリングはLLMの出力を制御する最も直接的な方法です：
- 長さを指定：「50文字以内で回答してください」
- 言語を指定：「日本語で回答してください」
- 形式とスタイルを指定

temperatureを上げると出力がよりランダムになり、長さや言語を制御する方法ではありません。

---

### Q12
**問題**：生成AIにおいて「temperature」パラメータの役割は何ですか？

A. モデルの訓練速度を制御する
B. 出力のランダム性/創造性を制御する
C. モデルが使用するGPUの数を制御する
D. 入力テキストの最大長を制御する

**✅ 解答：B - 出力のランダム性/創造性を制御する**

**解説**：Temperatureパラメータ：
- **温度=0**：最も確定的、最も保守的、最も一貫性がある
- **温度=0.5-0.7**：創造性と一貫性のバランス
- **温度=1**：標準サンプリング
- **温度>1**：非常にランダム、より創造的

---

### Q13
**問題**：大規模言語モデルがもっともらしく見えるが実際には不正確または架空の情報を生成する。この現象は何と呼ばれますか？

A. 過学習（Overfitting）
B. ハルシネーション（Hallucination）
C. バイアス（Bias）
D. ドリフト（Drift）

**✅ 解答：B - ハルシネーション（Hallucination）**

**解説**：LLMのハルシネーションとは：
- もっともらしく見えるが誤った情報を生成
- 存在しない事実、引用、データを捏造
- 不確実なことについて自信を持って発言

ハルシネーションを減らす方法：RAG、Grounding、temperatureを下げる

---

### Q14
**問題**：RAG（Retrieval-Augmented Generation）の主な利点は何ですか？

A. モデルの訓練時間を短縮する
B. モデルが最新の外部知識にアクセスできるようにする
C. モデルの推論速度を向上させる
D. モデルのパラメータ数を削減する

**✅ 解答：B - モデルが最新の外部知識にアクセスできるようにする**

**解説**：RAG（検索拡張生成）：
1. ナレッジベースから関連情報を検索
2. 情報をクエリと一緒にLLMに提供
3. LLMがコンテキストに基づいて回答を生成

利点：最新情報へのアクセス、ハルシネーションの削減、再訓練不要。

---

### Q15
**問題**：Amazon Bedrockにおいて「continued pre-training」と「fine-tuning」の主な違いは何ですか？

A. Continued pre-trainingはラベル付きデータを使用し、fine-tuningはラベルなしデータを使用する
B. Continued pre-trainingはラベルなしデータを使用し、fine-tuningはラベル付きデータを使用する
C. 両者は完全に同じ
D. Fine-tuningはモデルの重みを変更しない

**✅ 解答：B - Continued pre-trainingはラベルなしデータを使用し、fine-tuningはラベル付きデータを使用する**

**解説**：

| 方法 | データタイプ | 目的 |
|:-----|:---------|:-----|
| **Continued Pre-training** | ラベルなしデータ | モデルにドメイン知識を習得させる |
| **Fine-tuning** | ラベル付きデータ（入力-出力ペア） | 特定タスクのパフォーマンスを最適化 |

---

### Q16
**問題**：大規模言語モデルにおける「Token」の意味は何ですか？

A. 認証資格情報
B. モデルがテキストを処理する基本単位
C. APIキー
D. 課金通貨

**✅ 解答：B - モデルがテキストを処理する基本単位**

**解説**：Tokenは以下のようなものです：
- 完全な単語
- サブワード（例：「playing」→「play」+「ing」）
- 文字
- 英単語は約1-2トークン
- 日本語の1文字は約1-2トークン

---

### Q17
**問題**：LLMの出力をより確定的で一貫性のあるものにしたい場合、temperatureパラメータをどのように調整すべきですか？

A. temperatureを上げる
B. temperatureを下げる
C. temperatureを1に設定する
D. Temperatureは出力の一貫性とは無関係

**✅ 解答：B - temperatureを下げる**

**解説**：
- **低温度（0-0.3）** → 出力がより確定的、より一貫性がある、より保守的
- **高温度（0.7-1+）** → 出力がよりランダム、より多様、より創造的

---

### Q18
**問題**：以下のどのPrompt技術が複雑な推論タスクに最も適していますか？

A. Zero-shot prompting
B. Chain-of-thought prompting
C. One-shot prompting
D. Completion prompting

**✅ 解答：B - Chain-of-thought prompting**

**解説**：思考の連鎖プロンプト（Chain-of-thought）：
- モデルに段階的な推論を促す
- 数学、論理、多段階推論タスクに適している
- プロンプト内で推論プロセスを示す
- 例：「ステップバイステップで考えてみましょう...」

---

### Q19
**問題**：「コンテキストウィンドウ（Context Window）」とは何ですか？

A. モデルの訓練時間
B. モデルが処理できる最大トークン数
C. モデルの層数
D. モデルのパラメータ数

**✅ 解答：B - モデルが処理できる最大トークン数**

**解説**：コンテキストウィンドウの制限：
- 入力 + 出力の合計トークン数
- モデルによって異なる制限（4K、8K、32K、128Kなど）
- 処理できるドキュメントの長さに影響
- 制限を超えるコンテンツは切り捨てられる

---

### Q20
**問題**：以下のうち、LLMのハルシネーション問題を最も効果的に減らすものはどれですか？

A. モデルサイズを増やす
B. RAGを使用して関連コンテキストを提供する
C. temperatureを上げる
D. 訓練データを減らす

**✅ 解答：B - RAGを使用して関連コンテキストを提供する**

**解説**：ハルシネーションを減らす方法：
- ✅ RAGで真実の関連情報を提供
- ✅ temperatureを下げる
- ✅ 明確なプロンプト
- ✅ 信頼できるソースにGrounding
- ❌ temperatureを上げるとハルシネーションが悪化

---

### Q21
**問題**：Amazon Titanとは何ですか？

A. AWSのサーバーハードウェア
B. Amazonの基盤モデルシリーズ
C. データベースサービス
D. コンテナサービス

**✅ 解答：B - Amazonの基盤モデルシリーズ**

**解説**：Amazon Titanには以下が含まれます：
- Titan Text（テキスト生成）
- Titan Embeddings（ベクトル化）
- Titan Image Generator（画像生成）
- Titan Multimodal Embeddings
- Amazon Bedrockを通じてアクセス

---

### Q22
**問題**：Few-shot promptingにおいて「few-shot」とは何を指しますか？

A. 非常に少ない訓練データを使用すること
B. プロンプト内で少数の例を提供すること
C. モデルが非常に短い回答しか生成できないこと
D. 高速推論モード

**✅ 解答：B - プロンプト内で少数の例を提供すること**

**解説**：
- **Zero-shot**：例を提供せず、直接質問
- **One-shot**：1つの例を提供
- **Few-shot**：2-5個の例を提供
- 例はモデルがタスクの形式と期待される出力を理解するのに役立つ

---

## Domain 3: 基盤モデルのアプリケーション

---

### Q23
**問題**：ある法律事務所が大規模言語モデル（LLM）を使用してAIアプリケーションを構築したいと考えています。このアプリケーションは法的文書を読み、文書から重要なポイントを抽出します。どのソリューションがこれらの要件を満たしますか？

A. 自動名前付きエンティティ認識システムを構築する
B. レコメンデーションエンジンを作成する
C. 要約チャットボットを開発する
D. 多言語翻訳システムを開発する

**✅ 解答：C - 要約チャットボットを開発する**

**解説**：文書を読む + 重要なポイントを抽出する = 要約タスク
- 名前付きエンティティ認識はエンティティ名のみを識別し、重要なポイントを抽出しない
- レコメンデーションエンジンはコンテンツを推薦するためのもの
- 翻訳システムは言語変換のみを行う

---

### Q24
**問題**：ある企業がAmazon Bedrock上の基盤モデル（FM）を使用してチャットボットを作成したいと考えています。FMはAmazon S3バケットに保存された暗号化データにアクセスする必要があります。FMがS3データにアクセスしようとすると失敗が発生しています。最も可能性の高い原因は何ですか？

A. S3データの形式が正しくない
B. Bedrockのロールに復号化権限がない
C. プロンプトがうまく書かれていない
D. モデルが小さすぎる

**✅ 解答：B - Bedrockのロールに復号化権限がない**

**解説**：暗号化されたS3データにアクセスするには：
- S3読み取り権限（s3:GetObject）
- KMS復号化権限（kms:Decrypt）
- これはIAM権限設定の問題であり、データ形式やモデルの問題ではない

---

### Q25
**問題**：ある企業がAmazon SageMakerを本番環境のMLパイプラインとして使用しています。企業には最大1GBの大規模な入力データと最大1時間の処理時間があります。企業はほぼリアルタイムのレイテンシを必要としています。どのSageMaker推論オプションがこれらの要件を満たしますか？

A. リアルタイム推論（Real-time inference）
B. サーバーレス推論（Serverless inference）
C. 非同期推論（Asynchronous inference）
D. バッチ変換（Batch transform）

**✅ 解答：C - 非同期推論（Asynchronous inference）**

**解説**：

| オプション | 入力サイズ | 処理時間 | レイテンシ |
|:-----|:---------|:---------|:-----|
| リアルタイム推論 | <6MB | <60秒 | ミリ秒レベル |
| サーバーレス推論 | <4MB | <60秒 | コールドスタートあり |
| **非同期推論** | **最大1GB** | **最大1時間** | **ほぼリアルタイム** |
| バッチ変換 | 大 | 長い | 非リアルタイム |

---

### Q26
**問題**：ある企業がエッジデバイス上で言語モデルを使用して推論アプリケーションを作成したいと考えています。推論は可能な限り低いレイテンシである必要があります。どのソリューションがこれらの要件を満たしますか？

A. エッジデバイス上に最適化された小規模言語モデル（SLM）をデプロイする
B. エッジデバイス上に最適化された大規模言語モデル（LLM）をデプロイする
C. 集中型APIを使用して非同期通信する
D. クラウド上の大規模モデルをリアルタイムで呼び出す

**✅ 解答：A - エッジデバイス上に最適化された小規模言語モデル（SLM）をデプロイする**

**解説**：最低レイテンシには：
- ローカルデプロイメント（ネットワークレイテンシなし）
- 小規模モデル（推論が速く、リソース消費が少ない）
- 最適化されたSLMが最良の選択

LLMは大きすぎて、エッジデバイスのリソースでは実行できない。

---

### Q27
**問題**：ある企業が保護メガネの画像ラベリングを生成するソリューションを構築しています。ソリューションは高い精度を持ち、誤ったアノテーションのリスクを最小化する必要があります。どのソリューションがこれらの要件を満たしますか？

A. Amazon SageMaker Ground Truth Plusを使用してhuman-in-the-loop検証を行う
B. Amazon Bedrockナレッジベースを使用してデータ拡張を行う
C. Amazon Rekognitionを使用して画像認識を行う
D. Amazon QuickSight Qを使用してデータ要約を行う

**✅ 解答：A - Amazon SageMaker Ground Truth Plusを使用してhuman-in-the-loop検証を行う**

**解説**：Ground Truth Plusは：
- マネージドデータラベリングサービス
- 専門家チームによるレビュー
- human-in-the-loop検証で高精度を確保
- 誤ったラベリングを最小化

---

### Q28
**問題**：ある企業が製品画像からテキスト情報を抽出したいと考えています。どのAWSサービスを使用すべきですか？

A. Amazon Rekognition
B. Amazon Textract
C. Amazon Comprehend
D. Amazon Polly

**✅ 解答：B - Amazon Textract**

**解説**：AWSサービス比較：
- **Textract**：画像/PDFテキスト抽出（OCR）← 正解
- **Rekognition**：画像/動画分析（顔、物体検出）
- **Comprehend**：テキスト分析（感情、エンティティ）
- **Polly**：テキスト読み上げ

---

### Q29
**問題**：ある企業が顧客レビューの感情（ポジティブ/ネガティブ/ニュートラル）を分析したいと考えています。どのAWSサービスを使用すべきですか？

A. Amazon Lex
B. Amazon Comprehend
C. Amazon Transcribe
D. Amazon Translate

**✅ 解答：B - Amazon Comprehend**

**解説**：ComprehendはNLPサービスです：
- ✅ 感情分析（ポジティブ/ネガティブ/ニュートラル/混合）
- ✅ 名前付きエンティティ認識
- ✅ キーワード抽出
- ✅ 言語検出
- ✅ トピックモデリング

---

### Q30
**問題**：ある企業がカスタマーサービスの電話録音をテキストに変換したいと考えています。どのAWSサービスを使用すべきですか？

A. Amazon Polly
B. Amazon Transcribe
C. Amazon Comprehend
D. Amazon Textract

**✅ 解答：B - Amazon Transcribe**

**解説**：
- **Transcribe**：音声→テキスト（ASR/STT）← 正解
- **Polly**：テキスト→音声（TTS）
- 両者の機能は逆です！

覚え方：Transcribe = 転写 = 聞いたことを書き留める

---

### Q31
**問題**：ある企業がスマート検索機能を構築し、ユーザーが自然言語で内部ドキュメントを検索できるようにしたいと考えています。どのAWSサービスを使用すべきですか？

A. Amazon OpenSearch
B. Amazon Kendra
C. Amazon S3
D. Amazon DynamoDB

**✅ 解答：B - Amazon Kendra**

**解説**：Kendraはインテリジェントエンタープライズ検索です：
- 自然言語クエリの意図を理解
- リンクだけでなく回答を提供
- エンタープライズドキュメント検索向けに設計
- 複数のデータソース接続をサポート

OpenSearchは全文検索エンジンで、自然言語を理解しません。

---

### Q32
**問題**：あるEコマース企業がユーザーにパーソナライズされた製品推薦を提供したいと考えています。どのAWSサービスを使用すべきですか？

A. Amazon Comprehend
B. Amazon Personalize
C. Amazon Forecast
D. Amazon Lex

**✅ 解答：B - Amazon Personalize**

**解説**：Personalizeは以下に使用されます：
- パーソナライズされた製品推薦
- ユーザー行動に基づく学習
- Eコマース、コンテンツ推薦、マーケティングに適している

Forecastは時系列予測（売上予測）に使用され、推薦ではありません。

---

### Q33
**問題**：Amazon BedrockとAmazon SageMakerの主な違いは何ですか？

A. Bedrockはデータストレージに使用され、SageMakerは計算に使用される
B. Bedrockは事前訓練済み基盤モデルを提供し、SageMakerはカスタムモデルの構築に使用される
C. 両者の機能は完全に同じ
D. Bedrockはテキストのみをサポートし、SageMakerは画像のみをサポート

**✅ 解答：B - Bedrockは事前訓練済み基盤モデルを提供し、SageMakerはカスタムモデルの構築に使用される**

**解説**：
- **Bedrock**：事前訓練済み基盤モデルAPI、インフラ管理不要、迅速に使用可能
- **SageMaker**：完全なMLプラットフォーム、カスタムモデルの構築・訓練・デプロイ、より多くの制御

---

### Q34
**問題**：企業が顧客の意図を理解できるチャットボットを構築したいと考えています。どのAWSサービスを使用すべきですか？

A. Amazon Rekognition
B. Amazon Lex
C. Amazon Transcribe
D. Amazon Polly

**✅ 解答：B - Amazon Lex**

**解説**：Lexは会話型AIの構築に使用されます：
- 自然言語理解（NLU）
- 意図認識
- スロットフィリング
- 対話管理
- チャットボットの第一選択サービス

---

### Q35
**問題**：生成AIにおける「ベクトルデータベース（Vector Database）」の主な役割は何ですか？

A. リレーショナルデータを保存する
B. セマンティック検索をサポートするためにテキスト埋め込みベクトルを保存する
C. SQLクエリを実行する
D. ユーザー権限を管理する

**✅ 解答：B - セマンティック検索をサポートするためにテキスト埋め込みベクトルを保存する**

**解説**：生成AIにおけるベクトルデータベース：
- 埋め込みベクトル（embeddings）を保存
- セマンティック類似度検索をサポート
- RAGシステムのコアコンポーネント
- 例：Amazon OpenSearch Serverless Vector Engine

---

### Q36
**問題**：Amazon Qの主な用途は何ですか？

A. 従来のデータベースクエリ
B. AIアシスタント、質問への回答とワークタスクの支援
C. 画像生成
D. 音声合成

**✅ 解答：B - AIアシスタント、質問への回答とワークタスクの支援**

**解説**：Amazon Q：
- Q Business：エンタープライズナレッジQ&Aアシスタント
- Q Developer：プログラミング支援（GitHub Copilotに類似）
- 企業データに基づいて質問に回答
- エンタープライズ版AIアシスタントに類似

---

## Domain 4: 責任あるAIのガイドライン

---

### Q37
**問題**：以下のうち、責任あるAI（Responsible AI）のコア原則はどれですか？

A. モデル精度の最大化
B. 計算コストの削減
C. 公平性、透明性、説明可能性の確保
D. 最新のモデルアーキテクチャの使用

**✅ 解答：C - 公平性、透明性、説明可能性の確保**

**解説**：責任あるAIのコア原則：
- 公平性（Fairness）
- 透明性（Transparency）
- 説明可能性（Explainability）
- プライバシー保護（Privacy）
- セキュリティ（Security）
- アカウンタビリティ（Accountability）

---

### Q38
**問題**：AIにおける「バイアス（Bias）」とは何を指しますか？

A. モデルの訓練速度が遅すぎる
B. 特定のグループに対する不公平な扱いをもたらすシステム的なエラー
C. モデルが大量のデータを処理できない
D. モデルが多すぎる計算リソースを必要とする

**✅ 解答：B - 特定のグループに対する不公平な扱いをもたらすシステム的なエラー**

**解説**：AIバイアス：
- 特定のグループ（性別、人種、年齢など）に対する不公平
- 訓練データ内の歴史的バイアスに起因する可能性がある
- 不均一なデータサンプリングに起因する可能性がある
- SageMaker Clarifyを使用して検出する必要がある

---

### Q39
**問題**：Amazon SageMaker Clarifyの主な機能は何ですか？

A. モデル訓練速度の最適化
B. 機械学習モデルのバイアスを検出し、説明可能性を提供する
C. モデルを本番環境に自動デプロイする
D. ML実験のバージョンを管理する

**✅ 解答：B - 機械学習モデルのバイアスを検出し、説明可能性を提供する**

**解説**：SageMaker Clarify：
- バイアス検出（訓練前と訓練後）
- 説明可能性（SHAP値、特徴量重要度）
- 公平性モニタリング
- バイアスレポートの生成

---

### Q40
**問題**：Amazon Bedrock Guardrailsの主な用途は何ですか？

A. モデル推論速度の最適化
B. 安全でないまたは不適切なコンテンツのフィルタリングとブロック
C. AWS請求の管理
D. モデル訓練の自動化

**✅ 解答：B - 安全でないまたは不適切なコンテンツのフィルタリングとブロック**

**解説**：Bedrock Guardrails：
- コンテンツフィルタリング（有害、暴力、ヘイトコンテンツ）
- PII検出とマスキング
- トピック制限（特定のトピックのブロック）
- 語彙フィルタリング
- アプリケーション層でモデル出力を保護

---

### Q41
**問題**：あるデータサイエンスチームが、ローン承認モデルが女性申請者の承認率が男性よりも明らかに低いことを発見しました。これはどのような問題ですか？

A. 過学習
B. 未学習
C. モデルバイアス
D. データ漏洩

**✅ 解答：C - モデルバイアス**

**解説**：女性の承認率が男性より低い = ジェンダーバイアス
- 特定のグループに対するシステム的な不公平
- 歴史的データのバイアスに起因する可能性がある
- データとモデルの調査が必要
- Clarifyを使用して検出

---

### Q42
**問題**：AIアプリケーションにおいて、ユーザーのプライバシーを最もよく保護する方法は何ですか？

A. 最も強力なモデルを使用する
B. 個人識別情報（PII）のデータマスキングまたは匿名化
C. 訓練データ量を増やす
D. モデル精度を向上させる

**✅ 解答：B - 個人識別情報（PII）のデータマスキングまたは匿名化**

**解説**：プライバシー保護の方法：
- データマスキング/匿名化
- データ最小化（必要なデータのみ収集）
- 差分プライバシー
- 連合学習
- 暗号化処理

---

### Q43
**問題**：Amazon Bedrockを使用する際、モデルが会社で禁止されているトピックについて議論しないようにするにはどうすればよいですか？

A. モデルの重みを調整する
B. Bedrock Guardrailsを使用してトピックフィルタリングを設定する
C. モデルを再訓練する
D. 異なるモデルに切り替える

**✅ 解答：B - Bedrock Guardrailsを使用してトピックフィルタリングを設定する**

**解説**：Guardrailsでは：
- 「拒否するトピック」リストを設定
- 特定のトピックの議論をブロック
- モデルを変更する必要がない
- アプリケーション層で制御を実現

---

## Domain 5: セキュリティ、コンプライアンス、ガバナンス

---

### Q44
**問題**：AWS上でAIモデルデータを保護するベストプラクティスは何ですか？

A. すべてのデータを公開アクセス可能にする
B. AWS KMSを使用して静止データを暗号化し、TLSを使用して転送中のデータを暗号化する
C. すべてのデータをオンプレミスサーバーに保存する
D. パフォーマンスを向上させるために暗号化を使用しない

**✅ 解答：B - AWS KMSを使用して静止データを暗号化し、TLSを使用して転送中のデータを暗号化する**

**解説**：AWSデータセキュリティのベストプラクティス：
- 静止時の暗号化：AWS KMSでキーを管理
- 転送時の暗号化：TLS/SSL
- アクセス制御：IAM最小権限
- 監査ログ：CloudTrail

---

### Q45
**問題**：AWS共有責任モデル（Shared Responsibility Model）において、顧客が責任を負うのは何ですか？

A. 物理データセンターのセキュリティ
B. データの暗号化とアクセス制御
C. ネットワークインフラストラクチャのハードウェア
D. AWSサービスの可用性

**✅ 解答：B - データの暗号化とアクセス制御**

**解説**：共有責任モデル：
- **AWSの責任**：物理セキュリティ、インフラストラクチャ、ネットワークハードウェア
- **顧客の責任**：データ暗号化、アクセス制御、アプリケーションセキュリティ、IAM設定

---

### Q46
**問題**：AI/MLリソースへのアクセス権限を管理するために使用されるAWSサービスはどれですか？

A. Amazon S3
B. AWS IAM（Identity and Access Management）
C. Amazon SageMaker
D. Amazon Bedrock

**✅ 解答：B - AWS IAM（Identity and Access Management）**

**解説**：IAMは以下に使用されます：
- ユーザーとロールの管理
- 権限ポリシーの定義
- 最小権限の原則
- 多要素認証（MFA）
- 誰がどのAWSリソースにアクセスできるかを制御

---

### Q47
**問題**：AIガバナンスにおけるAWS CloudTrailの役割は何ですか？

A. 機械学習モデルを訓練する
B. 監査のためにAWS API呼び出しを記録・監視する
C. 訓練データを保存する
D. モデル推論パフォーマンスを最適化する

**✅ 解答：B - 監査のためにAWS API呼び出しを記録・監視する**

**解説**：CloudTrailは以下を提供します：
- すべてのAWS API呼び出しを記録
- 誰がいつ何をしたか
- コンプライアンス監査のサポート
- セキュリティ分析とトラブルシューティング

---

### Q48
**問題**：あるMLモデルが個人健康情報を含むデータセットを使用して訓練されました。HIPAAコンプライアンス要件に従って、どのような措置を講じるべきですか？

A. 追加の措置は不要
B. データ暗号化、アクセス制御を確保し、ビジネスアソシエイト契約（BAA）に署名する
C. データを非AWSサーバーに移動する
D. 透明性を高めるためにデータを公開する

**✅ 解答：B - データ暗号化、アクセス制御を確保し、ビジネスアソシエイト契約（BAA）に署名する**

**解説**：HIPAAコンプライアンス要件：
- データ暗号化（静止時と転送時）
- 厳格なアクセス制御
- 監査ログ
- AWSとBAA（ビジネスアソシエイト契約）に署名
- HIPAAコンプライアンスのAWSサービスを使用

---

### Q49
**問題**：Amazon Macieの主な機能は何ですか？

A. 機械学習モデルを訓練する
B. 機密データ（PIIなど）を自動的に発見、分類、保護する
C. コンテナデプロイメントを管理する
D. データベースパフォーマンスを最適化する

**✅ 解答：B - 機密データ（PIIなど）を自動的に発見、分類、保護する**

**解説**：Amazon Macie：
- S3内の機密データを自動スキャン
- PIIを識別（名前、住所、クレジットカード番号など）
- データの機密レベルを分類
- セキュリティ発見レポートを生成

---

### Q50
**問題**：あるMLモデルがテストセットで95%の精度を達成しましたが、本番環境ではパフォーマンスが悪いです。考えられる原因は何ですか？

A. モデルがシンプルすぎる
B. 訓練データと本番データの分布が異なる（データドリフト）
C. 評価指標が間違っている
D. テストセットが大きすぎる

**✅ 解答：B - 訓練データと本番データの分布が異なる（データドリフト）**

**解説**：データドリフト（Data Drift）：
- 訓練データの分布 ≠ 本番データの分布
- ユーザー行動の変化
- 季節的な変化
- SageMaker Model Monitorを使用して監視が必要
- モデルの再訓練が必要な場合がある

---

## 各ドメインスコア統計

| ドメイン | 問題範囲 | 正解数 | 満点 | 正解率 |
|------|---------|-----------|------|--------|
| Domain 1 | Q1-Q10 | ___/10 | 10 | ___% |
| Domain 2 | Q11-Q22 | ___/12 | 12 | ___% |
| Domain 3 | Q23-Q36 | ___/14 | 14 | ___% |
| Domain 4 | Q37-Q43 | ___/7 | 7 | ___% |
| Domain 5 | Q44-Q50 | ___/7 | 7 | ___% |
| **合計** | Q1-Q50 | ___/50 | 50 | ___% |

---

*試験頑張ってください！*
